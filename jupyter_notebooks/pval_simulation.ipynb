{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0869e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "from scipy import stats\n",
    "from scipy.stats import chisquare\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa421d7",
   "metadata": {},
   "source": [
    "# Pval simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b5a329",
   "metadata": {},
   "source": [
    "## Generation of random counts\n",
    "\n",
    "The following function generates a list of `n` random numbers selected from the range `[0, 1, 2, 3]` and converts them to a list of four counts (number of occurences of `0`, `1`, `2`, `3`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf07811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_counts(n:int):\n",
    "    sampled_list = []\n",
    "    for _ in range(n):\n",
    "        rval = sample([0, 1, 2, 3],1)\n",
    "        sampled_list.append(rval[0])\n",
    "    d = defaultdict(int)\n",
    "    d[0] = 0; d[1] = 0; d[2] = 0; d[3] = 0;\n",
    "    for x in sampled_list:\n",
    "        d[x] += 1\n",
    "    random_counts = []\n",
    "    for k,v in d.items():\n",
    "        random_counts.append(v)\n",
    "    return random_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa78ed75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[259, 236, 236, 269]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_counts = generate_random_counts(1000)\n",
    "random_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f1df80",
   "metadata": {},
   "source": [
    "This version of the function is simpler and more efficient, but still not efficient enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b57e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_counts_2(n:int):\n",
    "    sampled_list = list(np.random.choice([0, 1, 2, 3], size=n, p=[0.25,0.25,0.25,0.25]))\n",
    "    x = Counter(sampled_list)\n",
    "    return [x[0], x[1], x[2], x[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0873669f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[241, 250, 247, 262]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_counts_2 = generate_random_counts_2(1000)\n",
    "random_counts_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75be06a",
   "metadata": {},
   "source": [
    "### Generation of multiple random counts\n",
    "\n",
    "The two functions above generate random counts for just one interactions, calling a numpy sampling method each time. Calling such methods in Python is expensive. Therefore it is better to make only a few method calls and draw as many many random numbers as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3fe39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of simulated interactions\n",
    "i_num = 100000\n",
    "\n",
    "# Number of reads of each interaction\n",
    "rp_num = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e360e2d",
   "metadata": {},
   "source": [
    "Time consumption of the first method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ebf0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 3.7967689037323\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "random_counts_list = []\n",
    "for i in range(0, i_num):\n",
    "    random_counts_list.append(generate_random_counts(rp_num))\n",
    "    \n",
    "end = time.time()\n",
    "print('Time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fae206",
   "metadata": {},
   "source": [
    "Time consumption of the second improved method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a012350e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 4.16831111907959\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "random_counts_list = []\n",
    "for i in range(0, i_num):\n",
    "    random_counts_list.append(generate_random_counts_2(rp_num))\n",
    "    \n",
    "end = time.time()\n",
    "print('Time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab886de",
   "metadata": {},
   "source": [
    "Method with few calls of numpy random sampling methodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f6282db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.04401516914367676\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Get population of read pair types (0, 1, 2, 3)\n",
    "population_size = 1000000\n",
    "population = np.random.choice([0, 1, 2, 3], size=population_size, p=[0.25,0.25,0.25,0.25])\n",
    "\n",
    "end = time.time()\n",
    "print('Time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb5f1f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.014905691146850586\n",
      "Time: 1.9816792011260986\n"
     ]
    }
   ],
   "source": [
    "def count_four_types(random_sample):\n",
    "    indices, counts = np.unique(random_sample, return_counts=True)\n",
    "    random_counts = np.array([0, 0, 0, 0])\n",
    "    random_counts[indices] = counts\n",
    "    return random_counts    \n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Draw index samples for all interactions at once\n",
    "multi_sample_idx = np.random.randint(population_size - 1, size=(i_num, rp_num))\n",
    "#print(population[multi_sample_idx])\n",
    "\n",
    "end = time.time()\n",
    "print('Time: ' + str(end - start))\n",
    "start = time.time()\n",
    "\n",
    "# Determine read type counts for each simulated interaction\n",
    "random_counts_list = []\n",
    "for random_sample in population[multi_sample_idx]: # Runtime could be further improved with 'apply'\n",
    "    indices, counts = np.unique(random_sample, return_counts=True)\n",
    "    random_counts = np.array([0, 0, 0, 0])\n",
    "    random_counts[indices] = counts\n",
    "    random_counts_list.append(random_counts)\n",
    "\n",
    "# Alternative solutions with list comprehension and map (does not save any time)\n",
    "#random_counts_list = [count_four_types(random_sample) for random_sample in population[multi_sample_idx]]\n",
    "#random_counts_list = list(map(count_four_types, population[multi_sample_idx]))\n",
    "    \n",
    "end = time.time()\n",
    "print('Time: ' + str(end - start))\n",
    "#print(random_counts_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60c6afe",
   "metadata": {},
   "source": [
    "## Simple/Twisted binomial P-value\n",
    "\n",
    "The following function takes a list of four random counts, sums the counts for `0` and `1` and calculates a binomial P-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccbc1d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binom12(random_counts, verbose=False):\n",
    "    N = sum(random_counts)\n",
    "    K = random_counts[0] + random_counts[1]\n",
    "    pval = stats.binom_test(K, n=N, p=0.5, alternative='two-sided')\n",
    "    if verbose:\n",
    "        print('Randomly generated list of four counts: ' + str(random_counts))\n",
    "        print('Number of successes (K): ' + str(K))\n",
    "        print('Number of trials (N): ' + str(N))\n",
    "    return pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcce2d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly generated list of four counts: [5, 5, 4, 6]\n",
      "Number of successes (K): 10\n",
      "Number of trials (N): 20\n",
      "Binomial-01 P-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "pval = binom12(generate_random_counts_2(20), verbose=True)\n",
    "print('Binomial-01 P-value: ' + str(pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c51fc8",
   "metadata": {},
   "source": [
    "## Highest two counts binomial P-value\n",
    "\n",
    "The function above takes a list of four random counts, sums the highest two counts, and calculates a binomial P-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7945643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomHT(random_counts, verbose=False):\n",
    "    N = sum(random_counts)\n",
    "    sorted_counts = sorted(random_counts)\n",
    "    K = sum(sorted_counts[2:])\n",
    "    pval = stats.binom_test(K, n=N, p=0.5, alternative='greater')\n",
    "    if verbose:\n",
    "        print('Randomly generated list of four counts: ' + str(random_counts)) \n",
    "        print('Sorted four counts: ' + str(sorted_counts))\n",
    "        print('Number of successes (K): ' + str(K))\n",
    "        print('Number of trials (N): ' + str(N))   \n",
    "    return pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4e14a0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly generated list of four counts: [3, 8, 5, 4]\n",
      "Sorted four counts: [3, 4, 5, 8]\n",
      "Number of successes (K): 13\n",
      "Number of trials (N): 20\n",
      "Binomial-HT P-value: 0.13158798217773438\n"
     ]
    }
   ],
   "source": [
    "pval = binomHT(generate_random_counts_2(20), verbose=True)\n",
    "print('Binomial-HT P-value: ' + str(pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5274d8",
   "metadata": {},
   "source": [
    "## Chi-squared P-value\n",
    "\n",
    "The following function takes a list of four random counts and calculates a chi-squared P-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3be23525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chisq_pval(random_counts, verbose=False):\n",
    "    pval = stats.chisquare(f_obs=random_counts)[1]\n",
    "    if verbose:\n",
    "        print('Randomly generated list of four counts: ' + str(random_counts))     \n",
    "    return pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f27db910",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly generated list of four counts: [3, 5, 7, 5]\n",
      "Chi-square P-value: 0.6593898197119847\n"
     ]
    }
   ],
   "source": [
    "pval = chisq_pval(generate_random_counts_2(20), verbose=True)\n",
    "print('Chi-square P-value: ' + str(pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbfa5e6",
   "metadata": {},
   "source": [
    "## Problem with chi-square test and small counts\n",
    "\n",
    "The [documementation for the chi-square](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html) test states that the test is not valid if the counts are too small:\n",
    "\n",
    "*This test is invalid when the observed or expected frequencies in each category are too small. A typical rule is that all of the observed and expected frequencies should be at least 5. According to [3], the total number of samples is recommended to be greater than 13, otherwise exact tests (such as Barnard’s Exact test) should be used because they do not overreject.*\n",
    "\n",
    "This text was taken from the documentation of the chi-square goodness of fit test. However, Barnard's exact test is a test of independence that makes use of a contingency table to determine the independence of two factors. Therfore, Barnard's exact test is not adequate for our problem of defining unbalanced interactions. The text above should be placed in the documentation for the [chi-square test with contingency table](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html).\n",
    "\n",
    "For the data we are analyzing, there are many interactions with counts smaller than 5 and there are also interactions with total read counts that are smaller than 13, especially for Hi-C data. We therefore use the chi-square goodness of fit test only here for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868bbe78",
   "metadata": {},
   "source": [
    "## Comparison of different P-values\n",
    "\n",
    "We have a function that randomly generates a list of four random counts and four different ways of computing a P-value. The following code generates a certain number of random count lists and, for each list, all four P-values are calculated and added to lists. At the end, the number of P-values are determined that are below a specified P-value threshold. Because the lists were randomly generated, a certain number of tests can be expected to be signifcant. This number depends on the number of iterations and the P-value threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "22a9267e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reads per interaction: 20\n",
      "Number of simulations: 2,000\n",
      "P-value threshold: 0.05000\n",
      "Expected number of times 'significant': 100\n",
      "\n",
      "ST pval score times 'significant': 83\n",
      "\tActual threshold: 0.04150\n",
      "\tFold change: -1.20\n",
      "\n",
      "HT pval score times 'significant': 257\n",
      "\tActual threshold: 0.12850\n",
      "\tFold change: 2.57\n",
      "\n",
      "Chi-square pval times 'significant' : 88\n",
      "\tActual threshold: 0.04400\n",
      "\tFold change: -1.14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rp_total = 20        # Total number of reads per interaction\n",
    "iter_num = 2000     # Number of simulated counts quadruples\n",
    "pval_thresh = 0.05   # P-value threshold\n",
    "\n",
    "print(\"Total number of reads per interaction: \" + \"{:,}\".format(rp_total))\n",
    "print(\"Number of simulations: \" + \"{:,}\".format(iter_num))\n",
    "print(\"P-value threshold: \" + \"{:.5f}\".format(pval_thresh))\n",
    "\n",
    "# Lists of P-values for all simulated quadruples\n",
    "simplePvals = []\n",
    "htPvals = []\n",
    "chi2_pvals = []\n",
    "\n",
    "# Expected number of significant tests given the P-value threshold and the number of simuulations\n",
    "exp_nsig = int(iter_num*pval_thresh)\n",
    "print(\"Expected number of times 'significant': \" + \"{:,}\".format(exp_nsig))\n",
    "print()\n",
    "\n",
    "# Perform simualtions and calculate P-values of the different tests\n",
    "for _ in range(iter_num):\n",
    "    \n",
    "    # Get random quadruple\n",
    "    random_counts = generate_random_counts_2(rp_total)\n",
    "    \n",
    "    # Simple/Twisted    \n",
    "    pval = binom12(random_counts)\n",
    "    simplePvals.append(pval)\n",
    "    \n",
    "    # Heaviest two\n",
    "    pvalHT = binomHT(random_counts)\n",
    "    htPvals.append(pvalHT)\n",
    "    \n",
    "    # Chi-square godness of fit    \n",
    "    pvalChi2 = chisq_pval(random_counts)\n",
    "    chi2_pvals.append(pvalChi2)\n",
    "\n",
    "# Determine obeserved numbers of significant tests and compare them with the expected value\n",
    "st_nsig = sum([x<pval_thresh for x in simplePvals])\n",
    "fold_change = -exp_nsig/st_nsig if st_nsig < exp_nsig else st_nsig/exp_nsig\n",
    "print(\"ST pval score times 'significant': \" + str(st_nsig) + \"\\n\\tActual threshold: \" + \"{:.5f}\".format(st_nsig/iter_num) + \"\\n\\tFold change: \" + \"{:.2f}\".format(fold_change))\n",
    "print()\n",
    "ht_nsig = sum([x<pval_thresh for x in htPvals])\n",
    "fold_change = -exp_nsig/ht_nsig if ht_nsig < exp_nsig else ht_nsig/exp_nsig\n",
    "print(\"HT pval score times 'significant': \" + str(ht_nsig) + \"\\n\\tActual threshold: \" + \"{:.5f}\".format(ht_nsig/iter_num) + \"\\n\\tFold change: \" + \"{:.2f}\".format(fold_change))\n",
    "print()\n",
    "cq_nsig = sum([x<pval_thresh for x in chi2_pvals])\n",
    "fold_change = -exp_nsig/cq_nsig if cq_nsig < exp_nsig else cq_nsig/exp_nsig\n",
    "print(\"Chi-square pval times 'significant' : \" + str(cq_nsig) + \"\\n\\tActual threshold: \" + \"{:.5f}\".format(cq_nsig/iter_num) + \"\\n\\tFold change: \" + \"{:.2f}\".format(fold_change))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d59db",
   "metadata": {},
   "source": [
    "**P-value threshold: `0.05` and `20,000` simulations**\n",
    "```\n",
    "Total number of reads per interaction: 11\n",
    "Number of simulations: 20,000\n",
    "P-value threshold: 0.05000\n",
    "Expected number of times 'significant': 1,000\n",
    "\n",
    "ST pval score times 'significant': 221\n",
    "\tActual threshold: 0.01105\n",
    "\tFold change: -4.52\n",
    "\n",
    "HT pval score times 'significant': 3697\n",
    "\tActual threshold: 0.18485\n",
    "\tFold change: 3.70\n",
    "\n",
    "Chi-square pval times 'significant' : 845\n",
    "\tActual threshold: 0.04225\n",
    "\tFold change: -1.18\n",
    "```\n",
    "\n",
    "With the ST binomial model, the null hypothesis is rejected too often. The observed number of significant tests is about **five times smaller** than expected. With the HT binomial model, the null hypothesis is clearly under-rejected. The observed number of significant tests is **more than three times larger** than expected. With the chi-square godness of fit test, the observed number of significant tests is close to the expected number. The test is slightly over-rejecting the null hypothesis.\n",
    "\n",
    "**P-value threshold: `0.01` and `20,000` simulations**\n",
    "```\n",
    "Total number of reads per interaction: 11\n",
    "Number of simulations: 20,000\n",
    "P-value threshold: 0.01000\n",
    "Expected number of times 'significant': 200\n",
    "\n",
    "ST pval score times 'significant': 23\n",
    "\tActual threshold: 0.00115\n",
    "\tFold change: -8.70\n",
    "\n",
    "HT pval score times 'significant': 652\n",
    "\tActual threshold: 0.03260\n",
    "\tFold change: 3.26\n",
    "\n",
    "Chi-square pval times 'significant' : 109\n",
    "\tActual threshold: 0.00545\n",
    "\tFold change: -1.83\n",
    "```\n",
    "\n",
    "With the ST binomial model and a more stringent P-value threhold, the null hypothesis is rejected even more often. The observed number of significant tests is about **nine times smaller** than expected. With the HT binomial model, the null hypothesis is again clearly under-rejected. The observed number of significant tests is still **more than three times larger** than expected. With this more stringent P-value threshold, the chi-square godness of fit test is over-rejecting the null hypothesis. The observed number of significant tests is only half as large than expected.\n",
    "\n",
    "**P-value threshold: `0.01` and `100,000` simualtions**\n",
    "```\n",
    "Total number of reads per interaction: 11\n",
    "Number of simulations: 100,000\n",
    "P-value threshold: 0.01000\n",
    "Expected number of times 'significant': 1,000\n",
    "\n",
    "ST pval score times 'significant': 92\n",
    "\tActual threshold: 0.00092\n",
    "\tFold change: -10.87\n",
    "\n",
    "HT pval score times 'significant': 3560\n",
    "\tActual threshold: 0.03560\n",
    "\tFold change: 3.56\n",
    "\n",
    "Chi-square pval times 'significant' : 537\n",
    "\tActual threshold: 0.00537\n",
    "\tFold change: -1.86\n",
    "```\n",
    "\n",
    "Increasing the number of simualtions has little effect on the results.\n",
    "\n",
    "\n",
    "**P-value threshold: `0.005` and `200,000` simulations**\n",
    "\n",
    "```\n",
    "Total number of reads per interaction: 11\n",
    "Number of simulations: 200,000\n",
    "P-value threshold: 0.00500\n",
    "Expected number of times 'significant': 1,000\n",
    "\n",
    "ST pval score times 'significant': 195\n",
    "\tActual threshold: 0.00097\n",
    "\tFold change: -5.13\n",
    "\n",
    "HT pval score times 'significant': 584\n",
    "\tActual threshold: 0.00292\n",
    "\tFold change: -1.71\n",
    "\n",
    "Chi-square pval times 'significant' : 967\n",
    "\tActual threshold: 0.00483\n",
    "\tFold change: -1.03\n",
    "```\n",
    "\n",
    "We set the P-value thresholds for a given FDR threshold by randomizing interactions. That means we do not control the type I error for each individual test, but the rate of type I errors for multiple tests via the FDR. In our current analyzes, no P-value thresholds that were determined in this way were greater than `0.005`. For such stringent P-value thresholds, we do not observe that the HT model over-rejects the null hypothesis. In fact, the opposite is true, the observed number of significant interactions is even lower than the expected number.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The chi-square goodness-of-fit would be the most adequate test for our problem if we could assume that the counts for each category are greater than 5 and the sum of all counts greater than 13. According to the documentation, the test is considered invalid of this is not the case.\n",
    "\n",
    "For the data we analyze, we cannot make these assumptions.\n",
    "\n",
    "For the stringent P-value thresholds resulting from our FDR procedure, the number of significant simulated counts for the HT P-value score is below the expexted number.\n",
    "\n",
    "Interestingly, although the sum of our simulated random counts was only 11, so that the conditions for the tests can never be satisfied, the number of significant simulations was always the closest to the expected number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679772ae",
   "metadata": {},
   "source": [
    "## Adequacy of chi-square goodness-of-fit test\n",
    "\n",
    "The chi-square **goodness-of-fit** could be adequate for our problem. Here are the results for the same read counts we used for the Barnard's exact tests above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1359e7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=30.0, pvalue=1.3800570312932553e-06)\n",
      "Power_divergenceResult(statistic=30.0, pvalue=1.3800570312932553e-06)\n",
      "Power_divergenceResult(statistic=30.0, pvalue=1.3800570312932553e-06)\n",
      "Power_divergenceResult(statistic=30.0, pvalue=1.3800570312932553e-06)\n",
      "\n",
      "Power_divergenceResult(statistic=20.0, pvalue=0.00016974243555282632)\n",
      "Power_divergenceResult(statistic=20.0, pvalue=0.00016974243555282632)\n",
      "\n",
      "Power_divergenceResult(statistic=20.0, pvalue=0.00016974243555282632)\n",
      "Power_divergenceResult(statistic=20.0, pvalue=0.00016974243555282632)\n",
      "\n",
      "Power_divergenceResult(statistic=20.0, pvalue=0.00016974243555282632)\n",
      "Power_divergenceResult(statistic=20.0, pvalue=0.00016974243555282632)\n"
     ]
    }
   ],
   "source": [
    "print(stats.chisquare([10, 0, 0, 0])) # configuration 0X\n",
    "print(stats.chisquare([0, 10, 0, 0])) # configuration 1X\n",
    "print(stats.chisquare([0, 0, 10, 0])) # configuration 2X\n",
    "print(stats.chisquare([0, 0, 0, 10])) # configuration 3X\n",
    "print()\n",
    "print(stats.chisquare([10, 0, 10, 0])) # configuration 02\n",
    "print(stats.chisquare([10, 0, 0, 10])) # configuration 03\n",
    "print()\n",
    "print(stats.chisquare([0, 10, 10, 0])) # configuration 12\n",
    "print(stats.chisquare([0, 10, 0, 10])) # configuration 13\n",
    "print()\n",
    "print(stats.chisquare([10, 10, 0, 0])) # configuration 01\n",
    "print(stats.chisquare([0, 0, 10, 10])) # configuration 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a741dc72",
   "metadata": {},
   "source": [
    "Everything is absolutely symmetrical, which is good! There is one problem though. Interactions where the majority of read counts are of one particular type, get much smaller P-values than interactions where the majority of read counts are of only two types. This also applies if the total number of reads is the same and even if the interaction with the less extreme configuration has twice as many reads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c7924f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power_divergenceResult(statistic=30.0, pvalue=1.3800570312932553e-06)\n",
      "Power_divergenceResult(statistic=10.0, pvalue=0.01856613546304325)\n",
      "Power_divergenceResult(statistic=20.0, pvalue=0.00016974243555282632)\n"
     ]
    }
   ],
   "source": [
    "print(stats.chisquare([10, 0, 0, 0])) # configuration 0X\n",
    "print(stats.chisquare([5, 0, 5, 0]))  # configuration 02\n",
    "print(stats.chisquare([10, 0, 10, 0]))  # configuration 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341d3ae3",
   "metadata": {},
   "source": [
    "So far had only two counts. There were exactly two most extreme cases, in each of which one or the other count is zero. These two cases are also symmetric, meaning they yield the same P-value. For a given P-value threshold, we defined interactions as powered that have enough reads to be significant in the most extreme case. We determined the minimum number of reads required for significance by setting one count to zero and incrementing the other count. At each step, we calculated the P-value. If the P-value exeeded the threshold, we used the number of reads from the previous step to define powered interactions.\n",
    "\n",
    "With the new model using four counts, the most extreme case is where the majority of reads are of the same type. We just saw that the P-values for such configurations are much smaller than for configurations where the majority of reads are of two different types, even if the total number of reads is the same or twice as many. This results in a much larger number of powered interactions, which on average have fewer reads per interaction.\n",
    "\n",
    "Another even bigger problem is that the chi-square test requires that the counts in each category should be at least 5. For the analyzed data, this is often not the case. Therefore, we tried Barnard's exact test, but it turned out that this test is not adequate to define unbalanced interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45192a36",
   "metadata": {},
   "source": [
    "## Minimum number of reads required for powered interactions when using chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f7eccf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0]\n",
      "0.3916251762710877\n",
      "0.4071293966335873\n",
      "[2, 0, 0, 0]\n",
      "0.11161022509471268\n",
      "0.9522960159827726\n",
      "[3, 0, 0, 0]\n",
      "0.02929088653488826\n",
      "1.5332674835118683\n",
      "[4, 0, 0, 0]\n",
      "0.007383160505359769\n",
      "2.1317576901804918\n",
      "[5, 0, 0, 0]\n",
      "0.0018166489665723214\n",
      "2.740728983869122\n",
      "[6, 0, 0, 0]\n",
      "0.0004398496528388289\n",
      "3.356695746469692\n",
      "[7, 0, 0, 0]\n",
      "0.00010527618177149762\n",
      "3.977669874733538\n",
      "[8, 0, 0, 0]\n",
      "2.4979977724652003e-05\n",
      "4.6024079532343025\n",
      "[9, 0, 0, 0]\n",
      "5.887355583577668e-06\n",
      "5.230079732945775\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10,1):\n",
    "    increasing_counts = [i, 0, 0, 0]\n",
    "    print(increasing_counts)\n",
    "    pval = chisq_pval(increasing_counts)\n",
    "    print(pval)\n",
    "    if sys.float_info.min * sys.float_info.epsilon < pval:\n",
    "        print(-math.log10(pval))\n",
    "    else:\n",
    "        print('INF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d22b558",
   "metadata": {},
   "source": [
    "## Precision of P-values\n",
    "\n",
    "There is a limit to the precision that we must must consider in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7fde5507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323.3062153431158"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-math.log10(sys.float_info.min * sys.float_info.epsilon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diachrscripts",
   "language": "python",
   "name": "diachrscripts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

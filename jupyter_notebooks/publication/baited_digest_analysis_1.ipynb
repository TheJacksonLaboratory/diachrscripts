{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "184ddd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../..\")\n",
    "from diachr import DiachromaticInteractionSet\n",
    "from diachr import BaitedDigestSet\n",
    "\n",
    "# Create directory for output files generated in this notebook \n",
    "NOTEBOOK_RESULTS_DIR = 'bd_analysis_results'\n",
    "%mkdir -p $NOTEBOOK_RESULTS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807cd6c",
   "metadata": {},
   "source": [
    "# Classification of baited digests into BDC0, BDC1 or BDC2\n",
    "\n",
    "In this notebook, we divide baited digests into three classes BDC0, BDC1 and BDC2 based on whether type 2 or type 3 read pairs predominate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11346f3",
   "metadata": {},
   "source": [
    "## Input file with interactions\n",
    "\n",
    "The input is a file in `DiachromaticInteraction11` format created with the Python script `UICer.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04461a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR_SHORT = 'SCH' # JAV, SCH, MIF\n",
    "PROTOCOL = 'CHC' # HC or CHC\n",
    "CELL_TYPE_SHORT = 'MESC' # MK, ERY, NEU, MON, MAC_M0, ..., MESC, MFLC, MESC_R1ABKO, GM12878\n",
    "OUT_PREFIX = AUTHOR_SHORT + '_' + CELL_TYPE_SHORT + '_' + PROTOCOL +'_REPC'\n",
    "INTERACTION_FILE = '../../UICer_interactions/' + PROTOCOL + '/' + OUT_PREFIX + '_evaluated_and_categorized_interactions.tsv.gz' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905ff6a0",
   "metadata": {},
   "source": [
    "## Create  ``BaitedDigestSet``\n",
    "\n",
    "In a `BaitedDigestSet` object, interactions are grouped by chromosomes and baits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e267ad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Parsing Diachromatic interaction file ...\n",
      "\t[INFO] ../../UICer_interactions/CHC/SCH_MESC_CHC_REPC_evaluated_and_categorized_interactions.tsv.gz\n",
      "\t[INFO] Set size: 992,329\n",
      "[INFO] ... done.\n",
      "[INFO] Reading interactions and group them according to chromosomes and baited digests ...\n",
      "\t[INFO] Total number of interactions read: 992,329\n",
      "\t[INFO] Total number of baited digests: 19,157\n",
      "[INFO] ... done.\n",
      "[INFO] Report on ingestion of interactions:\n",
      "\t[INFO] Total number of interactions read: 992,329\n",
      "\t[INFO] Discarded NN and EE interactions: 104,635\n",
      "\t[INFO] Total number of ingested NE and EN interactions: 887,694\n",
      "\t[INFO] Broken down by interaction category and enrichment status: \n",
      "\t\t[INFO] DIX: \n",
      "\t\t\t[INFO] NE: 165\n",
      "\t\t\t[INFO] EN: 169\n",
      "\t\t[INFO] DI: \n",
      "\t\t\t[INFO] NE: 115,410\n",
      "\t\t\t[INFO] EN: 115,236\n",
      "\t\t[INFO] UIR: \n",
      "\t\t\t[INFO] NE: 115,612\n",
      "\t\t\t[INFO] EN: 115,034\n",
      "\t\t[INFO] UI: \n",
      "\t\t\t[INFO] NE: 213,959\n",
      "\t\t\t[INFO] EN: 212,109\n",
      "\t\t[INFO] ALL: \n",
      "\t\t\t[INFO] NE: 445,146\n",
      "\t\t\t[INFO] EN: 442,548\n",
      "\t[INFO] Total number of baited digests: 19,157\n",
      "[INFO] End of report.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create DiachromaticInteractionSet\n",
    "d11_interaction_set = DiachromaticInteractionSet()\n",
    "d11_interaction_set.parse_file(\n",
    "    i_file = INTERACTION_FILE,\n",
    "    verbose = True)\n",
    "# Create BaitedDigestSet\n",
    "baited_digest_set = BaitedDigestSet()\n",
    "read_interactions_info_dict = baited_digest_set.ingest_interaction_set(d11_interaction_set, verbose=True)\n",
    "print(baited_digest_set.get_ingest_interaction_set_info_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e910471d",
   "metadata": {},
   "source": [
    "## Determine frequencies of read pair types at individual baited digest\n",
    "\n",
    "The following function determines the frequencies of read pair types for a given list of interactions. We will use this function to determine the frequencies at individual baited digests by passing a list with all interactions that are associated with a specific baited digest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a44d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rpt_freq_dict(interaction_list):\n",
    "    \n",
    "    # Initialize count dictionary returned by this function\n",
    "    RPT_FREQ_DICT = dict()\n",
    "    for i_cat in ['DIX', 'DI', 'UIR', 'UI', 'ALL']:\n",
    "        RPT_FREQ_DICT[i_cat] = dict()\n",
    "        for e_cat in ['NN', 'EE', 'NE', 'EN', 'ALL']:\n",
    "            RPT_FREQ_DICT[i_cat][e_cat] = dict()\n",
    "            for rp_type in ['0', '1', '2', '3']:\n",
    "                RPT_FREQ_DICT[i_cat][e_cat][rp_type] = 0\n",
    "\n",
    "    # Get frequencies of read pair types\n",
    "    for d11_inter in interaction_list:\n",
    "        i_cat = d11_inter.get_category()\n",
    "        e_cat = d11_inter.enrichment_status_tag_pair\n",
    "        for rp_type in ['0', '1', '2', '3']:\n",
    "            if rp_type == '0':\n",
    "                rp_count = d11_inter._simple_1\n",
    "            elif rp_type == '1':\n",
    "                rp_count = d11_inter._simple_2\n",
    "            elif rp_type == '2':\n",
    "                rp_count = d11_inter._twisted_1\n",
    "            else:\n",
    "                rp_count = d11_inter._twisted_2\n",
    "            RPT_FREQ_DICT[i_cat][e_cat][rp_type] += rp_count\n",
    "            RPT_FREQ_DICT['ALL'][e_cat][rp_type] += rp_count \n",
    "            RPT_FREQ_DICT[i_cat]['ALL'][rp_type] += rp_count \n",
    "            RPT_FREQ_DICT['ALL']['ALL'][rp_type] += rp_count\n",
    "                    \n",
    "    return RPT_FREQ_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9612be",
   "metadata": {},
   "source": [
    "## Calculate baited digest score\n",
    "\n",
    "We use the following function to calculate to calculate a score for each baited digest. We first determine the sums of read pairs for type 2 and 3. Then we divide the smaller sum by the larger sum. To avoid divisions by zero, we add a pseudo count to both sums. If the score is smaller than a chosen threshold, then we assign the baited digests to the BDC1 or BDC2 class. If the sum of type 3 read pairs is larger then we assign the digests to class BDC1 and otherwise to BDC2. If the score is greater than the threshold, we assign the baited digest to the class BDC0, which is for digests without imbalances in the configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e931f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bd_score_and_class_rpt(RPT_FREQ_DICT, bds_threshold):\n",
    "    \n",
    "    # Get sum of read pairs of type 2\n",
    "    sum_rpt_2 = RPT_FREQ_DICT['2']\n",
    "\n",
    "    # Get sum of read pairs of type 3\n",
    "    sum_rpt_3 = RPT_FREQ_DICT['3']\n",
    "    \n",
    "    # Get total sum of read pairs\n",
    "    sum_rpt_total = sum(RPT_FREQ_DICT.values())\n",
    "    \n",
    "    # Calculate imbalanced configuration score\n",
    "    if sum_rpt_2 < sum_rpt_3:\n",
    "        bd_score = (sum_rpt_3 + 1)/(sum_rpt_2 + 1)\n",
    "        bd_class = 'BDC1'\n",
    "    else:\n",
    "        bd_score = (sum_rpt_2 + 1)/(sum_rpt_3 + 1)\n",
    "        bd_class = 'BDC2'\n",
    "\n",
    "    # No imbalances in the configurations\n",
    "    if bd_score < bds_threshold:\n",
    "        bd_class = 'BDC0'\n",
    "\n",
    "    return bd_score, bd_class, sum_rpt_3, sum_rpt_2, sum_rpt_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82b1cb",
   "metadata": {},
   "source": [
    "## Classify baited digests\n",
    "\n",
    "The following code iterates over all baited digests of a `BaitedDigestSet`. For each baited digest, a list of `NE` and `EN` interactions is retrieved and the function above is used to determine the frequencies of read types. From these frequencies, we calculate a score and assign the digest either to class BDC0, BDC1 or BDC2. For each of the three classes, we create a BED file that can be loaded into UCSC's genome browser. In the browser, BDC1 class digests are shown in blue, BDC2 class digests are shown green, and BDC0 class digests are shown gray. Digest ends that are predominantly sequenced are highlighted with thick ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afe57c3b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chromosome: chr13\n",
      "\tNumber of baited digests: 713\n",
      "\t\tBDC0: 266\n",
      "\t\tBDC1: 217\n",
      "\t\tBDC2: 230\n",
      "Chromosome: chr2\n",
      "\tNumber of baited digests: 1,603\n",
      "\t\tBDC0: 630\n",
      "\t\tBDC1: 478\n",
      "\t\tBDC2: 495\n",
      "Chromosome: chr5\n",
      "\tNumber of baited digests: 1,115\n",
      "\t\tBDC0: 434\n",
      "\t\tBDC1: 317\n",
      "\t\tBDC2: 364\n",
      "Chromosome: chr16\n",
      "\tNumber of baited digests: 639\n",
      "\t\tBDC0: 222\n",
      "\t\tBDC1: 209\n",
      "\t\tBDC2: 208\n",
      "Chromosome: chr8\n",
      "\tNumber of baited digests: 1,010\n",
      "\t\tBDC0: 359\n",
      "\t\tBDC1: 319\n",
      "\t\tBDC2: 332\n",
      "Chromosome: chr17\n",
      "\tNumber of baited digests: 806\n",
      "\t\tBDC0: 301\n",
      "\t\tBDC1: 242\n",
      "\t\tBDC2: 263\n",
      "Chromosome: chr6\n",
      "\tNumber of baited digests: 1,032\n",
      "\t\tBDC0: 411\n",
      "\t\tBDC1: 305\n",
      "\t\tBDC2: 316\n",
      "Chromosome: chr7\n",
      "\tNumber of baited digests: 1,483\n",
      "\t\tBDC0: 534\n",
      "\t\tBDC1: 462\n",
      "\t\tBDC2: 487\n",
      "Chromosome: chr14\n",
      "\tNumber of baited digests: 672\n",
      "\t\tBDC0: 254\n",
      "\t\tBDC1: 204\n",
      "\t\tBDC2: 214\n",
      "Chromosome: chr15\n",
      "\tNumber of baited digests: 763\n",
      "\t\tBDC0: 287\n",
      "\t\tBDC1: 237\n",
      "\t\tBDC2: 239\n",
      "Chromosome: chr4\n",
      "\tNumber of baited digests: 1,206\n",
      "\t\tBDC0: 447\n",
      "\t\tBDC1: 378\n",
      "\t\tBDC2: 381\n",
      "Chromosome: chr1\n",
      "\tNumber of baited digests: 1,170\n",
      "\t\tBDC0: 446\n",
      "\t\tBDC1: 332\n",
      "\t\tBDC2: 392\n",
      "Chromosome: chr9\n",
      "\tNumber of baited digests: 1,096\n",
      "\t\tBDC0: 428\n",
      "\t\tBDC1: 328\n",
      "\t\tBDC2: 340\n",
      "Chromosome: chr11\n",
      "\tNumber of baited digests: 1,615\n",
      "\t\tBDC0: 624\n",
      "\t\tBDC1: 443\n",
      "\t\tBDC2: 548\n",
      "Chromosome: chr3\n",
      "\tNumber of baited digests: 992\n",
      "\t\tBDC0: 374\n",
      "\t\tBDC1: 299\n",
      "\t\tBDC2: 319\n",
      "Chromosome: chr19\n",
      "\tNumber of baited digests: 594\n",
      "\t\tBDC0: 242\n",
      "\t\tBDC1: 179\n",
      "\t\tBDC2: 173\n",
      "Chromosome: chr12\n",
      "\tNumber of baited digests: 649\n",
      "\t\tBDC0: 273\n",
      "\t\tBDC1: 181\n",
      "\t\tBDC2: 195\n",
      "Chromosome: chrX\n",
      "\tNumber of baited digests: 557\n",
      "\t\tBDC0: 227\n",
      "\t\tBDC1: 154\n",
      "\t\tBDC2: 176\n",
      "Chromosome: chr10\n",
      "\tNumber of baited digests: 949\n",
      "\t\tBDC0: 361\n",
      "\t\tBDC1: 307\n",
      "\t\tBDC2: 281\n",
      "Chromosome: chr18\n",
      "\tNumber of baited digests: 493\n",
      "\t\tBDC0: 183\n",
      "\t\tBDC1: 150\n",
      "\t\tBDC2: 160\n",
      "\n",
      "Total number of baited digests: 19,157\n",
      "\tBDC0: 7,303\n",
      "\tBDC1: 5,741\n",
      "\tBDC2: 6,113\n"
     ]
    }
   ],
   "source": [
    "# If true, details are reported for each baited digests\n",
    "verbose = False\n",
    "\n",
    "# Threshold for baited digest score\n",
    "bds_threshold = 2\n",
    "\n",
    "# Interaction categories taken into account\n",
    "i_cat = 'ALL'\n",
    "\n",
    "# Directory for output\n",
    "OUT_DIR = NOTEBOOK_RESULTS_DIR + '/bdc_lists/' + AUTHOR_SHORT\n",
    "%mkdir -p $OUT_DIR\n",
    "\n",
    "# The coordinates of baited digests of classes BDC0, BDC1 and BDC2 are written to separate BED files\n",
    "BDC_FH2 = dict()\n",
    "BDC_NUM_T = dict()\n",
    "for bd_class in ['BDC0','BDC1','BDC2']:\n",
    "    BDC_FH2[bd_class] = open(OUT_DIR + '/' + OUT_PREFIX + '_' + bd_class.lower() + '.bed', 'w')\n",
    "    BDC_FH2[bd_class].write(\"track name=\\\"\" + OUT_PREFIX + \"_\" + bd_class.lower() + \"\\\" description=\\\"\" + OUT_PREFIX + \" \" + bd_class + \"\\\" itemRgb=\\\"On\\\"\" + '\\n')\n",
    "    BDC_NUM_T[bd_class] = 0\n",
    "\n",
    "# Iterate over all chromosomes\n",
    "for chrom in baited_digest_set._baited_digest_dict.keys():\n",
    "    \n",
    "    print('Chromosome: ' + chrom)\n",
    "    \n",
    "    # Numbers baited digests of classes BDC0, BDC1 and BDC2 on this chromosome\n",
    "    BDC_NUM_C = dict()\n",
    "    for i in ['BDC0','BDC1','BDC2']:\n",
    "        BDC_NUM_C[i] = 0\n",
    "    \n",
    "    # Iterate over all baited digests on this chromosome   \n",
    "    for baited_digest_key, baited_digest in baited_digest_set._baited_digest_dict[chrom].items():\n",
    "        \n",
    "        # Prepare list of NE and EN interactions that belong to this baited digest \n",
    "        interaction_list = baited_digest.interactions[i_cat]['NE'] + baited_digest.interactions[i_cat]['EN']\n",
    "\n",
    "        # Get frequencies of interactions\n",
    "        RPT_FREQ_DICT = get_rpt_freq_dict(interaction_list)\n",
    "        \n",
    "        # Calculate score and assign to a class       \n",
    "        bd_score, bd_class, sum_rpt_3, sum_rpt_2, sum_total = get_bd_score_and_class_rpt(\n",
    "            RPT_FREQ_DICT[i_cat]['ALL'],\n",
    "            bds_threshold)\n",
    "        \n",
    "        # Count baited digests of different classes\n",
    "        BDC_NUM_C[bd_class] += 1\n",
    "        BDC_NUM_T[bd_class] += 1\n",
    "        \n",
    "        # Get coordinates from key for output\n",
    "        chom, sta, end = baited_digest_key.split('\\t')\n",
    "        \n",
    "        # Format score for output\n",
    "        bd_score_formatted = \"{:.2f}\".format(bd_score)\n",
    "        \n",
    "        # Write coordinates and additional information to corresponding BED files        \n",
    "        name = bd_class + '|' + bd_score_formatted + ':' + str(sum_rpt_2) + ':' + str(sum_rpt_3) + ':' + str(sum_total)\n",
    "        BED_line = chom + '\\t' + sta + '\\t' + end + '\\t' + name + '\\t' + bd_score_formatted + '\\t' '.'\n",
    "        if bd_class == 'BDC0':\n",
    "            BED_line += '\\t' + sta + '\\t' + sta + '\\t' + '128,128,128' + '\\n'\n",
    "        elif bd_class == 'BDC1':\n",
    "            BED_line += '\\t' + sta + '\\t' + str(int(sta)+100) + '\\t' + '0,0,100' + '\\n'\n",
    "        elif bd_class == 'BDC2':\n",
    "            BED_line += '\\t' + str(int(end)-100) + '\\t' + end + '\\t' + '0,100,0' + '\\n'\n",
    "        else:\n",
    "            print('[ERROR] Invalid class ID: ' + bd_class + '!')\n",
    "        BDC_FH2[bd_class].write(BED_line)\n",
    "    \n",
    "        # Output details about each individual baited digest            \n",
    "        if verbose:\n",
    "            print('-------------------------')\n",
    "            print(baited_digest_key)\n",
    "            print('sum_rpt_2: ' + str(sum_rpt_2))\n",
    "            print('sum_rpt_3: ' + str(sum_rpt_3))\n",
    "            print('sum_total: ' + str(sum_total))\n",
    "            print('bd_class: ' + bd_class)            \n",
    "            print('bd_score: ' + bd_score_formatted)\n",
    "            print()\n",
    "            for rp_type in ['0', '1', '2', '3']:\n",
    "                for e_cat in ['ALL', 'NE','EN']:\n",
    "                    print(i_cat + '-' + e_cat + '-' + rp_type + ': ' + str(RPT_FREQ_DICT[i_cat][e_cat][rp_type]))\n",
    "                print()\n",
    "                \n",
    "    print('\\tNumber of baited digests: ' + \"{:,}\".format(sum(BDC_NUM_C.values())))\n",
    "    for bd_class in ['BDC0','BDC1','BDC2']:\n",
    "        print('\\t\\t' + bd_class  + \": {:,}\".format(BDC_NUM_C[bd_class]))\n",
    "\n",
    "print()\n",
    "print('Total number of baited digests: ' + \"{:,}\".format(sum(BDC_NUM_T.values())))\n",
    "for bd_class in ['BDC0','BDC1','BDC2']:\n",
    "    print('\\t' + bd_class  + \": {:,}\".format(BDC_NUM_T[bd_class]))\n",
    "    BDC_FH2[bd_class].close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011511dc",
   "metadata": {},
   "source": [
    "## Overlaps of baited fragments from classes BDC0, BDC1 and BDC2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755f852",
   "metadata": {},
   "source": [
    "### Select dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6da7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR_SHORT = 'SCH'\n",
    "CT_LIST = ['MESC', 'MFLC', 'MESC_R1ABKO']\n",
    "IN_DIR = NOTEBOOK_RESULTS_DIR + '/bdc_lists/' + AUTHOR_SHORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "840d429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR_SHORT = 'JAV'\n",
    "CT_LIST = ['MK', 'ERY', 'NEU', 'MON', 'MAC_M0', 'MAC_M1', 'MAC_M2', 'EP', 'NB', 'TB', 'FOET', 'NCD4', 'TCD4', 'NACD4', 'ACD4', 'NCD8', 'TCD8']\n",
    "IN_DIR = NOTEBOOK_RESULTS_DIR + '/bdc_lists/' + AUTHOR_SHORT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c099ad56",
   "metadata": {},
   "source": [
    "### Read baited fragments from files into data structure\n",
    "\n",
    "We generate a set of coordinates from each file. Each set can be accessed by cell type and BD class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73e06376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: bd_analysis_results/bdc_lists/JAV/JAV_MK_CHC_REPC_bdc0.bed\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bd_analysis_results/bdc_lists/JAV/JAV_MK_CHC_REPC_bdc0.bed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4611afa62010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reading file: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mf_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0md_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# discard header line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bd_analysis_results/bdc_lists/JAV/JAV_MK_CHC_REPC_bdc0.bed'"
     ]
    }
   ],
   "source": [
    "bd_dict = dict()\n",
    "for ct in CT_LIST:\n",
    "    bd_dict[ct] = dict()\n",
    "    for bdc in ['0', '1', '2']:\n",
    "        f_name = IN_DIR + '/' + AUTHOR_SHORT + '_' + ct + '_CHC_REPC' +'_bdc' + bdc + '.bed'\n",
    "        print('Reading file: ' + f_name)\n",
    "        d_set = set()\n",
    "        with open(f_name) as fh:\n",
    "            next(fh) # discard header line\n",
    "            for line in fh:\n",
    "                fields = line.rstrip().split('\\t')\n",
    "                d_key = fields[0] +':' + fields[1] + '-' + fields[2]\n",
    "                d_set.add(d_key)\n",
    "        #print('\\tNumber of digests: ' + str(len(d_set)))\n",
    "        bd_dict[ct][bdc] = d_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fef58b",
   "metadata": {},
   "source": [
    "### Get fraction of overlapping fragments for each pair of fragment sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763383df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "isect_prop_list = []\n",
    "for BDC_A in ['0', '1', '2']:\n",
    "    for CT_A in CT_LIST:\n",
    "        col_names = []\n",
    "        for BDC_B in ['0', '1', '2']:\n",
    "            for CT_B in CT_LIST:\n",
    "                isect_size = len(bd_dict[CT_A][BDC_A] & bd_dict[CT_B][BDC_B])\n",
    "                set_A_size = len(bd_dict[CT_A][BDC_A])\n",
    "                isect_prop_list.append(isect_size/set_A_size)\n",
    "                col_names.append(CT_B + '-BFC' + BDC_B)\n",
    "\n",
    "# Transform list to matrix and set row and column names\n",
    "isect_prop_matrix = np.reshape(isect_prop_list, (-1, len(col_names)))\n",
    "isect_prop_df = pd.DataFrame(data=isect_prop_matrix, columns=col_names)\n",
    "isect_prop_df.index = col_names\n",
    "#isect_prop_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ce052",
   "metadata": {},
   "source": [
    "### Create heatmap for overlap portions\n",
    "\n",
    "Note that this heatmap is not symmetrical and should be read as follows. A box in row `i` and column `j` indicates the proportion of fragments in set `i` that occur in both sets `i` and `j`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c55cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.color_palette(\"rocket_r\", as_cmap=True)\n",
    "sns.heatmap(isect_prop_df, square=True, cmap=cm, xticklabels=True, yticklabels=True)\n",
    "plt.tick_params(axis='both', which='major', labelsize=4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(IN_DIR + '/' + AUTHOR_SHORT + '_bdc_heatmap.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179e78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large heatmap for Javierre data\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "cm = sns.color_palette(\"rocket_r\", as_cmap=True)\n",
    "ax = sns.heatmap(isect_prop_df, square=True, cmap=cm, xticklabels=True, yticklabels=True)\n",
    "ax.tick_params(labelsize=12)\n",
    "ax.figure.axes[-1].tick_params(labelsize=29)\n",
    "plt.tight_layout()\n",
    "plt.savefig(IN_DIR + '/' + AUTHOR_SHORT + '_bdc_heatmap.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e93c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small heatmap for Schoenefelder data\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "cm = sns.color_palette(\"rocket_r\", as_cmap=True)\n",
    "ax = sns.heatmap(isect_prop_df, square=True, cmap=cm, xticklabels=True, yticklabels=True)\n",
    "ax.tick_params(labelsize=8)\n",
    "ax.figure.axes[-1].tick_params(labelsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(IN_DIR + '/' + AUTHOR_SHORT + '_bdc_heatmap_small.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diachrscripts",
   "language": "python",
   "name": "diachrscripts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
